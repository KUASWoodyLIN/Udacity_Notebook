{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH0 Hello Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woodylin/tensorflow3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello constant!'\n"
     ]
    }
   ],
   "source": [
    "hello_constant = tf.constant('Hello constant!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234) \n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([123,456,789]) \n",
    "# C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([ [123,456,789], [222,333,444] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello placeholder\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello placeholder'})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test String\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH1 Tensorflow Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.add(5, 2) #7 +\n",
    "x = tf.subtract(10, 4) #6 -\n",
    "x = tf.multiply(2, 5) #10 *\n",
    "x = tf.device(10) #5 /\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sub_4:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz : z = x / y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Convert the following to TensorFlow:\n",
    "x = tf.constant(10.0)\n",
    "y = tf.constant(2.0)\n",
    "z = tf.subtract(tf.divide(x, y), 1.0)\n",
    "# z = x/y - 1\n",
    "\n",
    "# TODO: Print z from a session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH2 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal distribtuion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```tf.truncated_normal()``` function returns a tensor with random values from a normal distribution whose magnitude is no more than 2 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```tf.zeros()``` function returns a tensor with all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 運行前須先初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH3 Linear Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    # TODO: Return weights\n",
    "    return tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "\n",
    "def get_biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    # TODO: Return biases\n",
    "    return tf.Variable(tf.zeros(n_labels))\n",
    "\n",
    "\n",
    "def linear(input, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param input: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(input, w), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features (28*28 image is 784 features)\n",
    "n_features = 784\n",
    "# Number of labels\n",
    "n_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and Biases\n",
    "w = get_weights(n_features, n_labels)\n",
    "b = get_biases(n_labels)\n",
    "\n",
    "# Linear Function xW + b\n",
    "logits = linear(features, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH4 Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Softmax](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a3b336_softmax/softmax.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [3.0, 1.0, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8360188 , 0.11314284, 0.05083836])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x) / np.exp(x).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.999546e-01 4.539787e-05 5.602542e-09]\n"
     ]
    }
   ],
   "source": [
    "logit_data = np.array([2.0, 1.0, 0.1]) * 10\n",
    "logits = tf.placeholder(tf.float32)\n",
    "\n",
    "softmax = tf.nn.softmax(logits)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH5 Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tf.reduce_sum()    ex: x = tf.reduce_sum([1, 2, 3, 4, 5])  # 15\n",
    "tf.log()           ex: x = tf.log(100)  # 4.60517\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_sum(tf.multiply(one_hot_data, tf.log(one_hot_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH6 Mini-batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "            \n",
    "    output_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        output_batches.append(batch)\n",
    "\n",
    "    return output_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['F11', 'F12', 'F13', 'F14'], ['F21', 'F22', 'F23', 'F24'], ['F31', 'F32', 'F33', 'F34']], [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]], [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n"
     ]
    }
   ],
   "source": [
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "example_batches = batches(3, example_features, example_labels)\n",
    "print(example_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH7 ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```output = tf.nn.relu(hidden_layer)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH8 Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two layer neural network\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580fe8f8_multi-layer/multi-layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "n_hidden_layer = 256 # layer number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']),\\\n",
    "    biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.01367\n",
      "96.27771\n",
      "85.77911\n",
      "69.87386\n",
      "52.89007\n",
      "49.851074\n",
      "46.314537\n",
      "48.204124\n",
      "46.868725\n",
      "32.291077\n",
      "33.305157\n",
      "33.102493\n",
      "27.801777\n",
      "25.823784\n",
      "28.524418\n",
      "32.244415\n",
      "21.939499\n",
      "28.488865\n",
      "23.307417\n",
      "20.327644\n",
      "18.6446\n",
      "25.905773\n",
      "19.769463\n",
      "22.974314\n",
      "24.01738\n",
      "18.539883\n",
      "16.200834\n",
      "19.359001\n",
      "15.087596\n",
      "16.299644\n",
      "18.35656\n",
      "12.592278\n",
      "13.254843\n",
      "15.816606\n",
      "16.690186\n",
      "10.92412\n",
      "17.389334\n",
      "12.71551\n",
      "15.222057\n",
      "21.660835\n",
      "15.431204\n",
      "15.164686\n",
      "12.437809\n",
      "13.970718\n",
      "13.563839\n",
      "10.75124\n",
      "12.746012\n",
      "12.622504\n",
      "15.413525\n",
      "15.688436\n",
      "12.470377\n",
      "15.414942\n",
      "10.399273\n",
      "17.516045\n",
      "11.42713\n",
      "12.66513\n",
      "12.254402\n",
      "14.391799\n",
      "9.102782\n",
      "8.022346\n",
      "11.862504\n",
      "16.277054\n",
      "9.896023\n",
      "13.899106\n",
      "10.468024\n",
      "10.74666\n",
      "9.934042\n",
      "9.378846\n",
      "12.094387\n",
      "11.922623\n",
      "15.744487\n",
      "14.655489\n",
      "9.235741\n",
      "11.377429\n",
      "7.233801\n",
      "12.637786\n",
      "13.589088\n",
      "10.573388\n",
      "7.5127726\n",
      "8.067748\n",
      "8.981442\n",
      "10.398941\n",
      "10.957452\n",
      "11.435812\n",
      "11.877391\n",
      "7.1902595\n",
      "11.480488\n",
      "10.264523\n",
      "6.353877\n",
      "8.672925\n",
      "9.773172\n",
      "8.836924\n",
      "11.007872\n",
      "10.313734\n",
      "10.969325\n",
      "8.356039\n",
      "9.3764925\n",
      "6.9340153\n",
      "5.7255707\n",
      "7.2284274\n",
      "8.261677\n",
      "7.288909\n",
      "10.484992\n",
      "11.166359\n",
      "7.238708\n",
      "6.7147675\n",
      "8.395903\n",
      "11.70874\n",
      "7.6315165\n",
      "8.11097\n",
      "7.9745536\n",
      "6.5610247\n",
      "6.9105186\n",
      "6.304845\n",
      "6.022745\n",
      "9.883158\n",
      "8.538126\n",
      "7.5094213\n",
      "7.1771164\n",
      "4.2849407\n",
      "4.3559213\n",
      "11.519409\n",
      "9.240946\n",
      "9.153856\n",
      "4.981705\n",
      "6.788067\n",
      "3.4472752\n",
      "5.245418\n",
      "8.083815\n",
      "7.2009172\n",
      "10.403929\n",
      "9.826214\n",
      "8.094354\n",
      "10.143771\n",
      "7.9230485\n",
      "11.170853\n",
      "6.344867\n",
      "4.6393805\n",
      "4.2106705\n",
      "9.49319\n",
      "5.3335676\n",
      "7.556912\n",
      "7.6402206\n",
      "7.3447895\n",
      "10.675232\n",
      "5.7975836\n",
      "6.7176037\n",
      "11.555935\n",
      "12.1037445\n",
      "7.562603\n",
      "10.988188\n",
      "8.534809\n",
      "6.3503075\n",
      "6.372878\n",
      "8.845521\n",
      "7.3664336\n",
      "8.911976\n",
      "10.116979\n",
      "7.921984\n",
      "7.0347853\n",
      "6.8140297\n",
      "6.021038\n",
      "4.677558\n",
      "3.0964599\n",
      "8.59886\n",
      "10.3636675\n",
      "6.520892\n",
      "8.385414\n",
      "5.176537\n",
      "8.211302\n",
      "8.756696\n",
      "5.938424\n",
      "6.0574646\n",
      "7.142616\n",
      "5.1880445\n",
      "6.9187098\n",
      "8.432636\n",
      "6.570521\n",
      "4.993514\n",
      "7.44424\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            if i % 50 == 0:\n",
    "                # to see the step improvement\n",
    "                print(sess.run(cost, feed_dict={x: batch_x, y: batch_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH9 Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving Variables**\n",
    "\n",
    "```saver = tf.train.Saver()```\n",
    "\n",
    "```saver.save(sess, save_file)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[1.1594137  0.1921379  0.28786567]\n",
      " [1.2608308  1.1085485  1.7127745 ]]\n",
      "Bias:\n",
      "[-0.5795733   0.7494573   0.27507132]\n"
     ]
    }
   ],
   "source": [
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Variables**\n",
    "\n",
    "```saver = tf.train.Saver()```\n",
    "\n",
    "```saver.restore(sess, save_file)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Weight:\n",
      "[[1.1594137  0.1921379  0.28786567]\n",
      " [1.2608308  1.1085485  1.7127745 ]]\n",
      "Bias:\n",
      "[-0.5795733   0.7494573   0.27507132]\n"
     ]
    }
   ],
   "source": [
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH10 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.dropout`\n",
    "\n",
    "ex: `hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)`\n",
    "\n",
    "The dropout function have two parameters:\n",
    "\n",
    "1. `hidden_layer`: 輸入層\n",
    "2. `keep_prob`: 保留多少比例的units\n",
    "\n",
    "注意: \n",
    "訓練資料時dropout prob 為0.5 (建議)\n",
    "\n",
    "測試資料時dropout prob 為1.0\n",
    "\n",
    "![比對圖](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/58222112_dropout-node/dropout-node.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.6799994 15.059999 ]\n",
      " [ 0.9100001  1.016    ]\n",
      " [ 4.72      28.32     ]]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow as tf\n",
    "\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model with Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "output_layer =tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "# TODO: Print logits from a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run(output_layer, feed_dict={keep_prob: 0.5})\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
