{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning 遷移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遷移學習中四大案例\n",
    "\n",
    "**根據**\n",
    "- 新的資料集的大小\n",
    "- 與原始資料的相識度\n",
    "\n",
    "**分為四種**\n",
    "- 新的資料集小、跟原始資料集相似\n",
    "- 新的資料集小、跟原始資料集不相似\n",
    "- 新的資料集大、跟原始資料集相似\n",
    "- 新的資料集大、跟原始資料集不相似\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a608ea_02-guide-how-transfer-learning-v3-01/02-guide-how-transfer-learning-v3-01.png)\n",
    "\n",
    "大的資料集必須有**一百萬張照片**\n",
    "小的資料集必虛有**兩千張照片**\n",
    "大小資料集之間的分界很主觀，當使用小數據集進行遷移學習時，過擬合是值得注意的問題。\n",
    "\n",
    "相似的資料集，像是**狗、狼**的關係，圖像會分享共同特徵\n",
    "不相似的資料集，像是**狗、花**的關係\n",
    "\n",
    "*四種遷移學習案例都有各自的方法*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Network 架構\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a73a2e_02-guide-how-transfer-learning-v3-02/02-guide-how-transfer-learning-v3-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Case 1: 小資料集、相似的資料\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a60b70_02-guide-how-transfer-learning-v3-03/02-guide-how-transfer-learning-v3-03.png)\n",
    "\n",
    "- 移除最後一層網絡\n",
    "- 新增新的一層新的全連接層（輸出與新的資料集一樣）\n",
    "- 新增加的全連接層使用隨機的weights，並凍結之前網絡的weights參數\n",
    "- 訓練網絡並更新最後一層weights\n",
    "\n",
    "避免在小資料集過擬合，原始網絡weights必須保持不變，而不是重新訓練權重。\n",
    "\n",
    "由於資料集相似，資料集再higher level conv layer**會有相識的特徵**。因此最後一層會重新連結這些特徵到輸出\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a73c8d_02-guide-how-transfer-learning-v3-04/02-guide-how-transfer-learning-v3-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Case 2: 小資料集、不相似的資料\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a60eaf_02-guide-how-transfer-learning-v3-05/02-guide-how-transfer-learning-v3-05.png)\n",
    "\n",
    "- 移除大部分的網絡，只保留前面小部份的網絡\n",
    "- 增加一個全連接層（輸出與新資料集一樣）\n",
    "- 新增加的全連接層使用隨機的weights，並凍結之前網絡的weights參數\n",
    "- 訓練網絡並更新最後一層weights\n",
    "\n",
    "避免在小資料集過擬合，原始網絡weights必須保持不變，而不是重新訓練權重。\n",
    "\n",
    "由於資料集不相似，所以在higher level conv layer**不會有相識的特徵**。再這種情況只能使用low level conv layer features。\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a73bd8_02-guide-how-transfer-learning-v3-06/02-guide-how-transfer-learning-v3-06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Case 3: 大資料集、相似的資料\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a6176d_02-guide-how-transfer-learning-v3-07/02-guide-how-transfer-learning-v3-07.png)\n",
    "\n",
    "- 移除最後一層網絡，並新增一層全連接層（輸出與新資料集一樣）\n",
    "- 新增加的全連接層使用隨機的weights\n",
    "- 其餘的網絡層使用預先訓練過得網絡參數\n",
    "- 重新訓練整個網絡模型\n",
    "\n",
    "在大資料集中訓練，過擬合部會造成太大的問題。你可以重新訓練所有的weights。\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a73ccd_02-guide-how-transfer-learning-v3-08/02-guide-how-transfer-learning-v3-08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Case 4: 大資料集、不相似的資料\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a61e66_02-guide-how-transfer-learning-v3-09/02-guide-how-transfer-learning-v3-09.png)\n",
    "\n",
    "1. 方法（一）：\n",
    "    - 移除最後一層網絡，並新增一層全連接層（輸出與新資料集一樣）\n",
    "    - 新增加的全連接層使用隨機的weights\n",
    "    - 其餘的網絡層使用預先訓練過得網絡參數\n",
    "    - 重新訓練整個網絡模型\n",
    "2. 方法（二）：\n",
    "    - 整個網絡使用隨機的weights\n",
    "    - 並重新訓練整個網絡\n",
    "\n",
    "即使新的資料集與訓練資料不同，從預先訓練的網絡初始化權重可能會使訓練數度更快。所以這種情況與大量類似資料集的情況玩相同\n",
    "\n",
    "如果使用預先訓練的網絡參數沒有好的結果，另一種選擇是隨機初始化整個網路並重頭開始訓練。\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a73d0d_02-guide-how-transfer-learning-v3-10/02-guide-how-transfer-learning-v3-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 總結\n",
    "---\n",
    "- Feature extraction (train only the top-level of the network, the rest of the network remains fixed)\n",
    "- Finetuning (train the entire network end-to-end, start with pre-trained weights)\n",
    "- Training from scratch (train the entire network end-to-end, start from random weights)\n",
    "---\n",
    "\n",
    "- 使用Feature extraction 的情況：\n",
    "    - 新的資料集小、跟原始資料集相似\n",
    "- 使用Finetuning 的情況：\n",
    "    - 新的資料集大、跟原始資料集相似，改變原始權重很安全，因為網絡很有可能在大資料集過擬合\n",
    "    - 新的資料集小、跟原始資料集不相似，當使用使用Finetune，只留下前面幾層網絡是個好主意\n",
    "- 使用training from scratch 的請況：\n",
    "    - 新的資料集大、跟原始資料集不相似\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
